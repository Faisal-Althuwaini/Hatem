import os
import chromadb
import numpy as np
import ollama
import torch
from sentence_transformers import SentenceTransformer

class ArabicRAGSystem:
    def __init__(self, 
                 text_file_path=None, 
                 db_path='./chroma_db', 
                 embedding_model='BAAI/bge-m3',  
                 ollama_model='qwen2'):
        """
        Initialize the RAG system with embedding-based retrieval and re-ranking.
        """
        os.makedirs(db_path, exist_ok=True)
        
        # Initialize ChromaDB with persistent storage
        self.chroma_client = chromadb.PersistentClient(path=db_path)
        self.collection_name = "arabic_documents"

        # Load embedding model (same for retrieval & re-ranking)
        self.embedding_model = SentenceTransformer(embedding_model)
        
        # Set LLM model
        self.ollama_model = ollama_model
        
        # Create collection if it doesn't exist
        try:
            self.collection = self.chroma_client.get_collection(name=self.collection_name)
        except:
            self.collection = self.chroma_client.create_collection(name=self.collection_name)

        # Process documents if provided
        if text_file_path and self.collection.count() == 0:
            self.process_documents(text_file_path)

    def format_based_chunking(self, text):
        """
        Splits text into chunks based on blank lines.
        Each paragraph remains a single chunk.
        """
        chunks = [chunk.strip() for chunk in text.split("\n\n") if chunk.strip()]
        return chunks

    def process_documents(self, file_path):
        """
        Reads, formats, chunks, embeds, and stores documents in ChromaDB.
        """
        print("Processing documents...")

        with open(file_path, 'r', encoding='utf-8') as file:
            text = file.read()

        # Use format-based chunking for better retrieval
        chunks = self.format_based_chunking(text)

        # Embed and store chunks
        for i, chunk in enumerate(chunks):
            embedding = self.embedding_model.encode(chunk).tolist()
            self.collection.add(
                embeddings=embedding,
                documents=[chunk],
                ids=[f"chunk_{i}"]
            )

        print(f"Processed {len(chunks)} chunks and stored in database.")

    def retrieve_relevant_context(self, query, top_k=2):
        """
        Retrieve the most relevant context for a given query using ChromaDB.
        """
        query_embedding = self.embedding_model.encode(query).tolist()

        # Retrieve initial results from ChromaDB (no re-ranking)
        results = self.collection.query(
            query_embeddings=query_embedding,
            n_results=top_k
        )

        # Ensure valid results
        if not results or 'documents' not in results or not results['documents']:
            print("âš ï¸ No relevant context found.")
            return []
        
        print("Retrived: ", results['documents'][0])

        return results['documents'][0]  # Directly return top-k documents
    
    def generate_response(self, query):
        """
        Generates a structured and precise response using retrieved and re-ranked context.
        """
        context = self.retrieve_relevant_context(query)

        # Structured Prompt
        prompt = f"""
    **ğŸ”¹ ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
    - Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© **Ø¯Ù‚ÙŠÙ‚Ø©** ØªØ¹ØªÙ…Ø¯ Ø­ØµØ±ÙŠÙ‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„:
    Ø¬Ø§ÙˆØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø¹Ø·Ù‰.
    ** Ø§Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø§ÙƒØ§Ø¯ÙŠÙ…ÙŠ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø­Ø§Ø¦Ù„ **
    ** Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© ØªØªØ¨Ø¹ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ù† 4 **
    ** Ø¬Ø§ÙˆØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬Ø§Ù…Ø¹Ø© Ø­Ø§Ø¦Ù„ **

    ğŸ”¹ **Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:**
    {''.join(context)}

    â“ **Ø§Ù„Ø³Ø¤Ø§Ù„:** {query}

    âœ… **Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:**
    1ï¸âƒ£ **Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬ÙˆØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡ Ø­Ø±ÙÙŠÙ‹Ø§ Ø£Ùˆ Ù‚Ù… Ø¨Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØªÙ‡ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØ¶ÙˆØ­.**
    2ï¸âƒ£ **Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø¬ÙˆØ§Ø¨ ÙˆØ§Ø¶Ø­Ù‹Ø§ØŒ ÙÙ‚Ù… Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© ÙˆÙ‚Ø¯Ù…Ù‡Ø§ Ø¨Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù…Ù…ÙƒÙ†Ø©.**
    3ï¸âƒ£ **ğŸš¨ Ù„Ø§ ÙŠØ¬ÙˆØ² Ù„Ùƒ Ø±ÙØ¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø·Ø§Ù„Ù…Ø§ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø°Ø§Øª ØµÙ„Ø© ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹.**
    4ï¸âƒ£ **ğŸš¨ Ù„Ø§ ÙŠØ¬ÙˆØ² Ù„Ùƒ Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø£Ùˆ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©.**
    5ï¸âƒ£ **Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø£ÙŠ Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªØŒ Ø¹Ù†Ø¯Ù‡Ø§ ÙÙ‚Ø· ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ù‚ÙˆÙ„: "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©."**
    """

        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[
                    {'role': 'system', 'content': 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·. ØªØ£ÙƒØ¯ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ù„ØªØ²Ù… Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¯ÙˆÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…Ø¤ÙƒØ¯Ø©.'},
                    {'role': 'user', 'content': prompt}
                ]
            )
            print("The prompt is : ", prompt)
            return response['message']['content']
        
        except Exception as e:
            print(f"Error generating response: {e}")
            return "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©."

# ----------------------------
#  Database Initialization & Query Execution
# ----------------------------

def initialize_database(file_path):
    """
    Initialize ChromaDB with formatted document storage.
    """
    rag_system = ArabicRAGSystem(text_file_path=file_path)
    print("Database initialized successfully.")

def query_database(query):
    """
    Query the system and return an accurate response.
    """
    rag_system = ArabicRAGSystem()
    return rag_system.generate_response(query)

# ----------------------------
#  Example Usage
# ----------------------------

def main():
    # Step 1: Initialize database (run once)
    initialize_database('university_rules_last.txt')
    
    # Step 2: Query the database
    query = "Ù…Ø§Ù‡ÙŠ Ø´Ø±ÙˆØ· Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØŸ" 
    response = query_database(query)
    print(response)

if __name__ == "__main__":
    main()
